## 1.
各种各样的网页有众多组成元素，例如图片、链接、文本、图形和动画，这种复杂的网页结构体也意味着抓取网页源代码的爬虫不一定能立刻获得你想要的信息。
所以在开始编写爬虫程序之前，你需要先计划清楚：
- 去哪里爬？
- 爬什么？

更专业一点的问法是：
- 目标网页的URL地址是哪里？
- 所需要的数据在于此URL地址传回网页源码结构的路径是什么？

第一个问题显然容易解决，没有人会不知道自己想要爬哪些数据。

第二个问题则可能有点难度，如果你有了解过html或者xml这种标记语言的知识，那你大概可以明白网页源码是一个树状结构。
一个比较合适的比喻是：html是网页的骨骼，javascript是网页的肌肉，css是网页的皮肤。
在我们现在面对这种比较简单的网页结构上，信息元素多半会存储于html上，即网页源代码，在使用requests获得网页源码后我们就可以对它进行解析，找到目标的位置。

举个例子：
这是一个html文件（内容即对应网页源码）
```
<html>
  <body>
    <div id="joe">hello joe</div>
    <div id="ben">hello ben</div>
  </body>
</html>

```
如果你想要抓取：
```hello joe```

你需要告诉计算机目标的位置是：
```html/body/div[id="joe"]/```

计算机根据你的位置就能一路搜索：
```<html>---<body>---<div id="joe">```
就能找到你所定位的标签，接下来便可以保存标签的内容或者其他所需的信息。这就是最基本的爬虫思路：获取源码——搜索元素——保存信息。

## 2.
